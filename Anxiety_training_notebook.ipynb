{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anxiety training notebook.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "KiNCjvbL-ffc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Desarrollo**"
      ]
    },
    {
      "metadata": {
        "id": "35ZPgQG15vtk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predicción del nivel de ansiedad mediante análisis de texto\n",
        "\n",
        "---\n",
        "\n",
        "El presente trabajo pretende entrenar un modelo de clasificación, que a partir de el anásis de texto, determine el nivel de ansiedad de una persona.  \n",
        "\n",
        "Se ha utilizado la base de datos [DAIC-WOZ](http://dcapswoz.ict.usc.edu/wwwutil_files/DAICWOZDepression_Documentation.pdf), de la Universidad del Sur de California, el mismo que fue generado mediante sesiones de una entrevista clínica y el cuestionario PHQ8 con 189 personas.  Las entrevista fue diseñada para el soporte al diagnóstico de condiciones de enfermedades sicológicas como ansiedad, depresión y desordenes de estrés post traumático.\n",
        "\n",
        "Los datos del dataset incluyen grabaciones de audio de las entrevitas con sus correspondientes transcripciones asi como las caracterísicas faciales de los sujetos entrevistados.\n",
        "\n",
        "Esta base de datos es parte de un corpus mas completo, Corpus de Entrevistas para el Análisis de Enfermedades, DAIC por sus siglas en inglés.  "
      ]
    },
    {
      "metadata": {
        "id": "_iw_TiMI-oy0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La base de datos consiste en un comprimido para cada sesión de entrevistas, en la misma constan varios recursos de los cuales en este trabajo de ha hecho uso de la transcripción de la entrevista, como preparación previa se ha cargado todas las entrevistas en un único dataframe de forma local con el siguiente código.  "
      ]
    },
    {
      "metadata": {
        "id": "QBKSNYF3CV24",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Método de carga de transcripts"
      ]
    },
    {
      "metadata": {
        "id": "7OGudeBuDO9w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Al considerar tanto al entrevistador como al participante, el conjunto de datos se reduce a las sesiones de 186 personas, dado que 3 transcripciones no contienen el texto correspondiente a Ellie, la entrevistadora virtual. El csv generado se ha subido a google drive para poder utilizarlo en este lab."
      ]
    },
    {
      "metadata": {
        "id": "mL_14jE8ACCF",
        "colab_type": "code",
        "outputId": "5690b199-c14f-4829-9faa-11f12c2e5558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "rows_list = []\n",
        "\n",
        "for filename in glob.iglob('/Volumes/Dev/Projects/Psicobotica/**/*TRANSCRIPT.csv', recursive=True):    \n",
        "    transcript = pd.read_csv(filename, sep='\\t')    \n",
        "    m = re.search('^\\/(.+\\/)*(\\d+)_TRANSCRIPT.csv', filename)    \n",
        "    personId = m.group(2)\n",
        "    p = {}\n",
        "    question = \"\"\n",
        "    answer = \"\"\n",
        "    lines = len(transcript)\n",
        "    for i in range(0, lines): \n",
        "        row=transcript.iloc[i]\n",
        "        if (row[\"speaker\"] == \"Ellie\" ) or (i == lines - 1):\n",
        "            p[\"personId\"] = personId\n",
        "            if (\"(\" in str(question)):\n",
        "                question = question[question.index(\"(\")+1:question.index(\")\")]\n",
        "            p[\"question\"] = question\n",
        "            p[\"answer\"] = answer\n",
        "            if (question != \"\"):\n",
        "                rows_list.append(p)\n",
        "            p = {}         \n",
        "            answer = \"\"\n",
        "            question = row[\"value\"]\n",
        "        else:\n",
        "            answer = str(answer) + \" \" + str(row[\"value\"])\n",
        "    \n",
        "allParticipants = pd.DataFrame(rows_list, columns=['personId', 'question', 'answer'])\n",
        "allParticipants.to_csv('/Volumes/Dev/Projects/practicas/all.csv', sep=',')\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nrows_list = []\\n\\nfor filename in glob.iglob(\\'/Volumes/Dev/Projects/Psicobotica/**/*TRANSCRIPT.csv\\', recursive=True):    \\n    transcript = pd.read_csv(filename, sep=\\'\\t\\')    \\n    m = re.search(\\'^\\\\/(.+\\\\/)*(\\\\d+)_TRANSCRIPT.csv\\', filename)    \\n    personId = m.group(2)\\n    p = {}\\n    question = \"\"\\n    answer = \"\"\\n    lines = len(transcript)\\n    for i in range(0, lines): \\n        row=transcript.iloc[i]\\n        if (row[\"speaker\"] == \"Ellie\" ) or (i == lines - 1):\\n            p[\"personId\"] = personId\\n            if (\"(\" in str(question)):\\n                question = question[question.index(\"(\")+1:question.index(\")\")]\\n            p[\"question\"] = question\\n            p[\"answer\"] = answer\\n            if (question != \"\"):\\n                rows_list.append(p)\\n            p = {}         \\n            answer = \"\"\\n            question = row[\"value\"]\\n        else:\\n            answer = str(answer) + \" \" + str(row[\"value\"])\\n    \\nallParticipants = pd.DataFrame(rows_list, columns=[\\'personId\\', \\'question\\', \\'answer\\'])\\nallParticipants.to_csv(\\'/Volumes/Dev/Projects/practicas/all.csv\\', sep=\\',\\')\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "metadata": {
        "id": "A2OedEZoT7v9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Instalo las librerias utilizadas"
      ]
    },
    {
      "metadata": {
        "id": "mtMIOfjmUDlN",
        "colab_type": "code",
        "outputId": "c4ff3694-08d7-42a0-d83a-ff437527a16e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gensim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: snowballstemmer in /usr/local/lib/python3.6/dist-packages (1.2.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZB_TLkFX5oXB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Importo las librerias requeridas para el desarrollo del trabajo"
      ]
    },
    {
      "metadata": {
        "id": "uhPdWaz7h2tx",
        "colab_type": "code",
        "outputId": "1781f37d-d542-4221-8884-5f77f313a6cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import fnmatch\n",
        "import os\n",
        "import keras\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, Activation, GlobalAveragePooling1D, Flatten, Concatenate, Conv1D, MaxPooling1D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.optimizers import SGD, RMSprop, Adagrad, Adam\n",
        "from keras.preprocessing.text import one_hot, text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from string import punctuation\n",
        "from scipy import stats\n",
        "\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import itertools\n",
        "import gensim\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DvGsHRW4kkCp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Descargamos los recursos de nltk, wordnet y stopwords para el procesamiento de lenguaje natural"
      ]
    },
    {
      "metadata": {
        "id": "axhc_8DG05hv",
        "colab_type": "code",
        "outputId": "d68d621b-ff16-4250-f83e-2a49efb7a987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TXW7miNilfVn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Habilito uso de drive para cargar los datasets"
      ]
    },
    {
      "metadata": {
        "id": "Oy6nsx_9kC6K",
        "colab_type": "code",
        "outputId": "9cb26d6b-e85d-4249-acaa-b463398aa34b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "maf7WJu6cJlq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Variable generales"
      ]
    },
    {
      "metadata": {
        "id": "6f4cF5JGksYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En base a la clasificación propuesta en https://www.torbayandsouthdevon.nhs.uk/uploads/score-sheet-gad-7-anxiety-and-phq-9-depression.pdf, se definen 5 niveles de ansiedad basados en la puntuación PHQ8"
      ]
    },
    {
      "metadata": {
        "id": "UNTpKYGtcINy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "labels=['none','mild','moderate','moderately severe', 'severe']\n",
        "num_classes = len(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3lg9jcPbm71",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Funciones para gráficas de modelos"
      ]
    },
    {
      "metadata": {
        "id": "o3Wd1PmgbuJP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tomadas de la materia Sistemas Cognitivos Artificiales - Alfredo Lainez"
      ]
    },
    {
      "metadata": {
        "id": "LIhakC2Pbr4U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_acc(history, title=\"Model Accuracy\"):\n",
        "    \"\"\"Imprime una gráfica mostrando la accuracy por epoch obtenida en un entrenamiento\"\"\"\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()\n",
        "    \n",
        "def plot_loss(history, title=\"Model Loss\"):\n",
        "    \"\"\"Imprime una gráfica mostrando la pérdida por epoch obtenida en un entrenamiento\"\"\"\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper right')\n",
        "    plt.show()\n",
        "    \n",
        "def plot_compare_losses(history1, history2, name1=\"Red 1\",\n",
        "                        name2=\"Red 2\", title=\"Graph title\"):\n",
        "    \"\"\"Compara losses de dos entrenamientos con nombres name1 y name2\"\"\"\n",
        "    plt.plot(history1.history['loss'], color=\"green\")\n",
        "    plt.plot(history1.history['val_loss'], 'r--', color=\"green\")\n",
        "    plt.plot(history2.history['loss'], color=\"blue\")\n",
        "    plt.plot(history2.history['val_loss'], 'r--', color=\"blue\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train ' + name1, 'Val ' + name1, \n",
        "                'Train ' + name2, 'Val ' + name2],\n",
        "               loc='upper right')\n",
        "    plt.show()\n",
        "    \n",
        "def plot_compare_accs(history1, history2, name1=\"Red 1\",\n",
        "                      name2=\"Red 2\", title=\"Graph title\"):\n",
        "    \"\"\"Compara accuracies de dos entrenamientos con nombres name1 y name2\"\"\"\n",
        "    plt.plot(history1.history['acc'], color=\"green\")\n",
        "    plt.plot(history1.history['val_acc'], 'r--', color=\"green\")\n",
        "    plt.plot(history2.history['acc'], color=\"blue\")\n",
        "    plt.plot(history2.history['val_acc'], 'r--', color=\"blue\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train ' + name1, 'Val ' + name1, \n",
        "                'Train ' + name2, 'Val ' + name2], \n",
        "               loc='lower right')\n",
        "    plt.show()\n",
        "\n",
        "def plot_compare_multiple_metrics(history_array, names, colors, title=\"Graph title\", metric='acc'):  \n",
        "    legend = []\n",
        "    for i in range(0, len(history_array)):\n",
        "        plt.plot(history_array[i].history[metric], color=colors[i])\n",
        "        plt.plot(history_array[i].history['val_' + metric], 'r--', color=colors[i])\n",
        "        legend.append('Train ' + names[i])\n",
        "        legend.append('Val ' + names[i])\n",
        "    \n",
        "    plt.title(title)\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')   \n",
        "    plt.axis\n",
        "    plt.legend(legend, \n",
        "               loc='lower right')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rU6ki8KClt-h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Carga y preprocesamiento de transcripciones"
      ]
    },
    {
      "metadata": {
        "id": "3O1UDoziKxE2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Carga de fuentes de datos\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Cargo el dataset que contiene solo las respuestas de los participantes"
      ]
    },
    {
      "metadata": {
        "id": "Z57zoWiofioa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cargo el transcript de la entrevistadora virtual y los participantes"
      ]
    },
    {
      "metadata": {
        "id": "2UchIdRhV_dR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_participants = pd.read_csv('/content/drive/My Drive/Colab Notebooks/all.csv', sep=',')\n",
        "all_participants.columns =  ['index','personId', 'question', 'answer']\n",
        "all_participants = all_participants.astype({\"index\": float, \"personId\": float, \"question\": str, \"answer\": str })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fAyRf7zVD3AN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualizo los primeros datos de los dataframes cargados."
      ]
    },
    {
      "metadata": {
        "id": "APMmmXa-WtBj",
        "colab_type": "code",
        "outputId": "84ff22a9-2694-4090-bdfb-883c53f3763f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "all_participants.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>personId</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>hi i'm ellie thanks for coming in today i was ...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>okay</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>so how are you doing today</td>\n",
              "      <td>good thank you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>that's good</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>where are you from originally</td>\n",
              "      <td>el segundo right down the street</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  personId                                           question  \\\n",
              "0    0.0     475.0  hi i'm ellie thanks for coming in today i was ...   \n",
              "1    1.0     475.0                                               okay   \n",
              "2    2.0     475.0                         so how are you doing today   \n",
              "3    3.0     475.0                                        that's good   \n",
              "4    4.0     475.0                      where are you from originally   \n",
              "\n",
              "                              answer  \n",
              "0                                yes  \n",
              "1                                nan  \n",
              "2                     good thank you  \n",
              "3                                nan  \n",
              "4   el segundo right down the street  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "RpWRRu9jcm31",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Analisis de datos"
      ]
    },
    {
      "metadata": {
        "id": "s1LGkOSAckLa",
        "colab_type": "code",
        "outputId": "44098279-0ab5-43ca-d72f-1e64ce5e38a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "ds_len = len(all_participants)\n",
        "len_answers = [len(v) for v in all_participants['answer']]\n",
        "ds_max = max(len_answers)\n",
        "ds_min = min(len_answers)\n",
        "\n",
        "stats.describe(len_answers)\n",
        "plt.hist(len_answers)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFKCAYAAAA0WNeQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGIZ4AwBgGOINAIBhiDcAAIb5P85DTrqXa+xrAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7feacf0edd30>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "1dASiIAenIxE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La mayor cantidad de frases tiene una longitud de 50 palabras"
      ]
    },
    {
      "metadata": {
        "id": "_gYd68nzOvaC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Funciones auxiliares para procesamiento de texto"
      ]
    },
    {
      "metadata": {
        "id": "WjhvDJXdl9Ah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#####Función tomada de kaggle para limpieza de texto"
      ]
    },
    {
      "metadata": {
        "id": "i4pwBVnEkztS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The function \"text_to_wordlist\" is from\n",
        "# https://www.kaggle.com/currie32/quora-question-pairs/the-importance-of-cleaning-text\n",
        "def text_to_wordlist(text, remove_stopwords=True, stem_words=False):    \n",
        "    # Clean the text, with the option to remove stopwords and to stem words.\n",
        "    \n",
        "    # Convert words to lower case and split them\n",
        "    text = text.lower().split()\n",
        "\n",
        "    # Optionally, remove stop words\n",
        "    if remove_stopwords:\n",
        "        stops = set(stopwords.words(\"english\"))\n",
        "        text = [wordnet_lemmatizer.lemmatize(w) for w in text if not w in stops ]\n",
        "        text = [w for w in text if w != \"nan\" ]\n",
        "    \n",
        "    text = \" \".join(text)\n",
        "\n",
        "    # Clean the text\n",
        "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
        "    text = re.sub(r\"what's\", \"what is \", text)\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"cannot \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\",\", \" \", text)\n",
        "    text = re.sub(r\"\\.\", \" \", text)\n",
        "    text = re.sub(r\"!\", \" ! \", text)\n",
        "    text = re.sub(r\"\\/\", \" \", text)\n",
        "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "    text = re.sub(r\"\\+\", \" + \", text)\n",
        "    text = re.sub(r\"\\-\", \" - \", text)\n",
        "    text = re.sub(r\"\\=\", \" = \", text)\n",
        "    \n",
        "    text = re.sub(r\"\\<\", \" \", text)\n",
        "    text = re.sub(r\"\\>\", \" \", text)\n",
        "    \n",
        "    text = re.sub(r\"'\", \" \", text)\n",
        "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
        "    text = re.sub(r\":\", \" : \", text)\n",
        "    text = re.sub(r\" e g \", \" eg \", text)\n",
        "    text = re.sub(r\" b g \", \" bg \", text)\n",
        "    text = re.sub(r\" u s \", \" american \", text)\n",
        "    text = re.sub(r\"\\0s\", \"0\", text)\n",
        "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
        "    text = re.sub(r\"e - mail\", \"email\", text)\n",
        "    text = re.sub(r\"j k\", \"jk\", text)\n",
        "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "    \n",
        "    # Optionally, shorten words to their stems\n",
        "    if stem_words:\n",
        "        text = text.split()\n",
        "        stemmer = SnowballStemmer('english')\n",
        "        stemmed_words = [stemmer.stem(word) for word in text]\n",
        "        text = \" \".join(stemmed_words)\n",
        "    \n",
        "    # Return a list of words\n",
        "    return(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "39fDkysCqpug",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Identificamos el número de palabras distintas"
      ]
    },
    {
      "metadata": {
        "id": "2F1WkFZYOGcc",
        "colab_type": "code",
        "outputId": "ee620768-5b81-4321-bc0b-a8c1ed6de56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "words = [w for w in all_participants_mix['answer'].tolist()]\n",
        "words = set(itertools.chain(*words))\n",
        "vocab_size = len(words)\n",
        "print(\"El tamaño del vocabulario es de {}\".format(vocab_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "El tamaño del vocabulario es de 7373\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "N6aaOW8mqxGG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preprocesamos los datos de entrada:\n",
        "\n",
        "\n",
        "*   Limpieza de texto\n",
        "*   Lematización\n",
        "*   Separación en vectores\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "zJW6YW0WxwRg",
        "colab_type": "code",
        "outputId": "47894f54-9e17-40a4-febc-aee2ff2dc0c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "all_participants_mix = all_participants.copy()\n",
        "all_participants_mix['answer'] = all_participants_mix.apply(lambda row: text_to_wordlist(row.answer).split(), axis=1)\n",
        "\n",
        "windows_size = 10\n",
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(all_participants_mix['answer'])\n",
        "tokenizer.fit_on_sequences(all_participants_mix['answer'])\n",
        "\n",
        "all_participants_mix['t_answer'] = tokenizer.texts_to_sequences(all_participants_mix['answer'])\n",
        "all_participants_mix.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>personId</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>t_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>hi i'm ellie thanks for coming in today i was ...</td>\n",
              "      <td>[yes]</td>\n",
              "      <td>[39]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>okay</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>so how are you doing today</td>\n",
              "      <td>[good, thank]</td>\n",
              "      <td>[16, 173]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>that's good</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>475.0</td>\n",
              "      <td>where are you from originally</td>\n",
              "      <td>[el, segundo, right, street]</td>\n",
              "      <td>[2246, 4302, 47, 827]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  personId                                           question  \\\n",
              "0    0.0     475.0  hi i'm ellie thanks for coming in today i was ...   \n",
              "1    1.0     475.0                                               okay   \n",
              "2    2.0     475.0                         so how are you doing today   \n",
              "3    3.0     475.0                                        that's good   \n",
              "4    4.0     475.0                      where are you from originally   \n",
              "\n",
              "                         answer               t_answer  \n",
              "0                         [yes]                   [39]  \n",
              "1                            []                     []  \n",
              "2                 [good, thank]              [16, 173]  \n",
              "3                            []                     []  \n",
              "4  [el, segundo, right, street]  [2246, 4302, 47, 827]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "metadata": {
        "id": "u47-_XmirBQr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verificamo el diccionario creado por el tokenizer"
      ]
    },
    {
      "metadata": {
        "id": "MWT0xDoA2pYW",
        "colab_type": "code",
        "outputId": "6241f44b-7e86-4b99-e645-ca9d2e411da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index\n",
        "word_size = len(word_index)\n",
        "print(word_index[\"happy\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7b2GriAtrQk4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generamos un nuevo dataset creando vectores de las palabras tokenizadas con un tamaño de ventana de 10 palabras"
      ]
    },
    {
      "metadata": {
        "id": "ZNDQBi-uxzbG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "windows_size = 10\n",
        "cont = 0\n",
        "word_index = tokenizer\n",
        "phrases_lp = pd.DataFrame(columns=['personId','answer', 't_answer'])\n",
        "answers = all_participants_mix.groupby('personId').agg('sum', axis=1)\n",
        "\n",
        "for p in answers.iterrows():      \n",
        "    words = p[1][\"answer\"]\n",
        "    size = len(words)\n",
        "    word_tokens = p[1][\"t_answer\"]\n",
        " \n",
        "    for i in range(size):\n",
        "        sentence = words[i:min(i+windows_size,size)]  \n",
        "        tokens = word_tokens[i:min(i+windows_size,size)]  \n",
        "        phrases_lp.loc[cont] = [p[0], sentence, tokens]\n",
        "        cont = cont + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tOXd7dyvrb9O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verificamos el contenido del nuevo dataset"
      ]
    },
    {
      "metadata": {
        "id": "Mx5sHZp5yqs2",
        "colab_type": "code",
        "outputId": "caabb39d-f271-4789-a6aa-888f4fcbb1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "phrases_lp.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>answer</th>\n",
              "      <th>t_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300.0</td>\n",
              "      <td>[good, atlanta, georgia, um, parent, um, love,...</td>\n",
              "      <td>[16, 1650, 2022, 1, 131, 1, 63, 5, 143, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300.0</td>\n",
              "      <td>[atlanta, georgia, um, parent, um, love, like,...</td>\n",
              "      <td>[1650, 2022, 1, 131, 1, 63, 5, 143, 5, 337]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300.0</td>\n",
              "      <td>[georgia, um, parent, um, love, like, weather,...</td>\n",
              "      <td>[2022, 1, 131, 1, 63, 5, 143, 5, 337, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>300.0</td>\n",
              "      <td>[um, parent, um, love, like, weather, like, op...</td>\n",
              "      <td>[1, 131, 1, 63, 5, 143, 5, 337, 1, 39]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>300.0</td>\n",
              "      <td>[parent, um, love, like, weather, like, opport...</td>\n",
              "      <td>[131, 1, 63, 5, 143, 5, 337, 1, 39, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   personId                                             answer  \\\n",
              "0     300.0  [good, atlanta, georgia, um, parent, um, love,...   \n",
              "1     300.0  [atlanta, georgia, um, parent, um, love, like,...   \n",
              "2     300.0  [georgia, um, parent, um, love, like, weather,...   \n",
              "3     300.0  [um, parent, um, love, like, weather, like, op...   \n",
              "4     300.0  [parent, um, love, like, weather, like, opport...   \n",
              "\n",
              "                                      t_answer  \n",
              "0   [16, 1650, 2022, 1, 131, 1, 63, 5, 143, 5]  \n",
              "1  [1650, 2022, 1, 131, 1, 63, 5, 143, 5, 337]  \n",
              "2     [2022, 1, 131, 1, 63, 5, 143, 5, 337, 1]  \n",
              "3       [1, 131, 1, 63, 5, 143, 5, 337, 1, 39]  \n",
              "4       [131, 1, 63, 5, 143, 5, 337, 1, 39, 1]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "4-sUVdlQrgeZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En caso de existir frases de dimensión menor aplicamos padding para tener vectores uniformes"
      ]
    },
    {
      "metadata": {
        "id": "D8FZg-N891pg",
        "colab_type": "code",
        "outputId": "9864b03e-cc5b-4ea2-e756-c5bb4ec25308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "phrases_lp[\"t_answer\"] = pad_sequences(phrases_lp[\"t_answer\"], value=0, padding=\"post\", maxlen=windows_size).tolist()\n",
        "phrases_lp.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>personId</th>\n",
              "      <th>answer</th>\n",
              "      <th>t_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300.0</td>\n",
              "      <td>[good, atlanta, georgia, um, parent, um, love,...</td>\n",
              "      <td>[16, 1650, 2022, 1, 131, 1, 63, 5, 143, 5]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>300.0</td>\n",
              "      <td>[atlanta, georgia, um, parent, um, love, like,...</td>\n",
              "      <td>[1650, 2022, 1, 131, 1, 63, 5, 143, 5, 337]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>300.0</td>\n",
              "      <td>[georgia, um, parent, um, love, like, weather,...</td>\n",
              "      <td>[2022, 1, 131, 1, 63, 5, 143, 5, 337, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>300.0</td>\n",
              "      <td>[um, parent, um, love, like, weather, like, op...</td>\n",
              "      <td>[1, 131, 1, 63, 5, 143, 5, 337, 1, 39]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>300.0</td>\n",
              "      <td>[parent, um, love, like, weather, like, opport...</td>\n",
              "      <td>[131, 1, 63, 5, 143, 5, 337, 1, 39, 1]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   personId                                             answer  \\\n",
              "0     300.0  [good, atlanta, georgia, um, parent, um, love,...   \n",
              "1     300.0  [atlanta, georgia, um, parent, um, love, like,...   \n",
              "2     300.0  [georgia, um, parent, um, love, like, weather,...   \n",
              "3     300.0  [um, parent, um, love, like, weather, like, op...   \n",
              "4     300.0  [parent, um, love, like, weather, like, opport...   \n",
              "\n",
              "                                      t_answer  \n",
              "0   [16, 1650, 2022, 1, 131, 1, 63, 5, 143, 5]  \n",
              "1  [1650, 2022, 1, 131, 1, 63, 5, 143, 5, 337]  \n",
              "2     [2022, 1, 131, 1, 63, 5, 143, 5, 337, 1]  \n",
              "3       [1, 131, 1, 63, 5, 143, 5, 337, 1, 39]  \n",
              "4       [131, 1, 63, 5, 143, 5, 337, 1, 39, 1]  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Ao0X5PZrysKO"
      },
      "cell_type": "markdown",
      "source": [
        "##Carga de resultados del cuestionario PHQ8 de los participantes"
      ]
    },
    {
      "metadata": {
        "id": "b-LGdAn1EFJg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preparo una función para cargar los archivos correspondientes a las puntuaciones de cada persona respecto al questionario PHQ8, este método categoriza la variable Score, en 5 niveles de acuerdo al rango especificado en el trabajo [Validity of a Brief Depression Severity Measure](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1495268/)"
      ]
    },
    {
      "metadata": {
        "id": "kaDz89vRqkCv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_avec_dataset_file(path, score_column):\n",
        "  ds = pd.read_csv(path, sep=',')\n",
        "  ds['level'] = pd.cut(ds[score_column], bins=[-1,0,5,10,15,25], labels=[0,1,2,3,4])\n",
        "  ds['PHQ8_Score'] = ds[score_column]\n",
        "  ds['cat_level'] = keras.utils.to_categorical(ds['level'], num_classes).tolist()\n",
        "  ds = ds[['Participant_ID', 'level', 'cat_level', 'PHQ8_Score']]\n",
        "  ds = ds.astype({\"Participant_ID\": float, \"level\": int, 'PHQ8_Score': int})\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "beflqiqnl0y4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cargo el dataset que contiene los resultados PHQ8 de todos los participantes, los datos han sido separados en archivos correspondientes a Train, Dev y Test."
      ]
    },
    {
      "metadata": {
        "id": "ZECsDuehlUnt",
        "colab_type": "code",
        "outputId": "42e3a01c-790f-487c-8668-fd78e7944aa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "train = load_avec_dataset_file('/content/drive/My Drive/Colab Notebooks/train_split_Depression_AVEC2017.csv', 'PHQ8_Score')\n",
        "dev = load_avec_dataset_file('/content/drive/My Drive/Colab Notebooks/dev_split_Depression_AVEC2017.csv', 'PHQ8_Score')\n",
        "test = load_avec_dataset_file('/content/drive/My Drive/Colab Notebooks/full_test_split.csv', 'PHQ_Score')\n",
        "print(\"Longitud: entrenamiento= {}, validacion= {}, test= {}\".format(len(train), len(dev), len(test)))\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitud: entrenamiento= 107, validacion= 35, test= 47\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Participant_ID</th>\n",
              "      <th>level</th>\n",
              "      <th>cat_level</th>\n",
              "      <th>PHQ8_Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>303.0</td>\n",
              "      <td>0</td>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>304.0</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>305.0</td>\n",
              "      <td>2</td>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0]</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>310.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>312.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0, 0.0]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Participant_ID  level                  cat_level  PHQ8_Score\n",
              "0           303.0      0  [1.0, 0.0, 0.0, 0.0, 0.0]           0\n",
              "1           304.0      2  [0.0, 0.0, 1.0, 0.0, 0.0]           6\n",
              "2           305.0      2  [0.0, 0.0, 1.0, 0.0, 0.0]           7\n",
              "3           310.0      1  [0.0, 1.0, 0.0, 0.0, 0.0]           4\n",
              "4           312.0      1  [0.0, 1.0, 0.0, 0.0, 0.0]           2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "sQlFLh-2GNUO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fusiono los datasets en uno solo"
      ]
    },
    {
      "metadata": {
        "id": "Z66uyop8sQTI",
        "colab_type": "code",
        "outputId": "816842ba-9c46-4888-a6f9-1e90218262d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "ds_total = pd.concat([train,dev,test])\n",
        "total_phq8 = len(ds_total)\n",
        "print(\"Longitud total = {}\".format(total_phq8))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longitud total = 189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xGmRLdzTP8wp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Preparación de datos para el entrenamiento"
      ]
    },
    {
      "metadata": {
        "id": "_AIyzl0dJ7NS",
        "colab_type": "code",
        "outputId": "cb78a9be-7060-4d7e-ce84-7af113196bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        " # Generamos una gráfica con las distribuciones del conjunto de entrenamiento\n",
        "bins=[-1,0,5,10,15,25]\n",
        "plt.hist(ds_total[\"PHQ8_Score\"], rwidth=0.6, bins=5)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFKCAYAAABcq1WoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAkAx8QWAYuILAMX+A9tXuz6sTHzjAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fea3b8b2908>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "vuna6ftMN00q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En la gráfica se visualiza una clara mayoria en la categoria mild cuya puntuación PHQ8 es mayor que 0 y menor que 5"
      ]
    },
    {
      "metadata": {
        "id": "AP_MEn_eOLa6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "####separación de datasets por puntaje PHQ8"
      ]
    },
    {
      "metadata": {
        "id": "spbabvn7r7zg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Función que separa los registros del dataset acorde el nivel de ansiedad"
      ]
    },
    {
      "metadata": {
        "id": "sFz6a306o1L5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_by_phq_level(ds):\n",
        "  none_ds = ds[ds['level']==0]\n",
        "  mild_ds = ds[ds['level']==1]\n",
        "  moderate_ds = ds[ds['level']==2]\n",
        "  moderate_severe_ds = ds[ds['level']==3]\n",
        "  severe_ds = ds[ds['level']==4]\n",
        "  return (none_ds, mild_ds, moderate_ds, moderate_severe_ds, severe_ds)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PteK8Eu7suPm",
        "colab_type": "code",
        "outputId": "df7b9a9e-017b-4ce7-e3e2-5ab0c3ababc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "none_ds, mild_ds, moderate_ds, moderate_severe_ds, severe_ds = split_by_phq_level(ds_total)\n",
        "print(\"Cantidad por none_ds: {}, mild_ds: {}, moderate_ds {}, moderate_severe_ds: {}, severe_ds {}\".format(len(none_ds), len(mild_ds), len(moderate_ds), len(moderate_severe_ds), len(severe_ds)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad por none_ds: 26, mild_ds: 70, moderate_ds 47, moderate_severe_ds: 24, severe_ds 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BJI2UalYOcrj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Distribución balanceada de los datos del conjunto de prueba"
      ]
    },
    {
      "metadata": {
        "id": "2xhRr5etsE2H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generamos un dataset con un número de registros balanceado entre todos los niveles de ansiedad"
      ]
    },
    {
      "metadata": {
        "id": "qNQgeF7jbebW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "b_none_ds = ds_total[ds_total['level']==0]\n",
        "b_mild_ds = ds_total[ds_total['level']==1].sample(26)\n",
        "b_moderate_ds = ds_total[ds_total['level']==2].sample(26)\n",
        "b_moderate_severe_ds = ds_total[ds_total['level']==3]\n",
        "b_severe_ds = ds_total[ds_total['level']==4]\n",
        "\n",
        "ds_total_b = pd.concat([b_none_ds, b_mild_ds, b_moderate_ds, b_moderate_severe_ds, b_severe_ds])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FE09DzKksRhR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Fusionamos el dataset de transcripciones con los resultados del test PHQ8"
      ]
    },
    {
      "metadata": {
        "id": "8KzwrRZd1SyX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ds_lp = pd.merge(ds_total, phrases_lp,left_on='Participant_ID', right_on='personId')\n",
        "ds_lp_b = pd.merge(ds_total_b, phrases_lp,left_on='Participant_ID', right_on='personId')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ifgL5JxdOlTK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####método para separar unificar los data sets por niveles, y distribuirlos en conjunto de entrenamiento, validación y pruebas"
      ]
    },
    {
      "metadata": {
        "id": "v6i6kE4jumbS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def distribute_instances(ds):\n",
        "    ds_shuffled = ds.sample(frac=1)\n",
        "    none_ds, mild_ds, moderate_ds, moderate_severe_ds, severe_ds = split_by_phq_level(ds_shuffled)\n",
        "    split = [70,14,16]\n",
        "    eq_ds = {}\n",
        "    prev_none = prev_mild = prev_moderate = prev_moderate_severe = prev_severe = 0\n",
        "\n",
        "    for p in split:\n",
        "      last_none = min(len(none_ds), prev_none + round(len(none_ds) * p/100))\n",
        "      last_mild = min(len(mild_ds), prev_mild + round(len(mild_ds) * p/100))\n",
        "      last_moderate = min(len(moderate_ds), prev_moderate + round(len(moderate_ds) * p/100))\n",
        "      last_moderate_severe = min(len(moderate_severe_ds), prev_moderate_severe + round(len(moderate_severe_ds) * p/100))\n",
        "      last_severe = min(len(severe_ds), prev_severe + round(len(severe_ds) * p/100))  \n",
        "      eq_ds[\"d\"+str(p)] = pd.concat([none_ds[prev_none: last_none], mild_ds[prev_mild: last_mild], moderate_ds[prev_moderate: last_moderate], moderate_severe_ds[prev_moderate_severe: last_moderate_severe], severe_ds[prev_severe: last_severe]])\n",
        "      prev_none = last_none\n",
        "      prev_mild = last_mild\n",
        "      prev_moderate = last_moderate\n",
        "      prev_moderate_severe = last_moderate_severe\n",
        "      prev_severe = last_severe  \n",
        "    return (eq_ds[\"d70\"], eq_ds[\"d14\"], eq_ds[\"d16\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OkIcB-zSsfXQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generación de conjuntos de entrenamiento, validación y prueba"
      ]
    },
    {
      "metadata": {
        "id": "BrlTUKFk1YjW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_lp, dev_lp, test_lp = distribute_instances(ds_lp)\n",
        "train_lp_b, dev_lp_b, test_lp_b = distribute_instances(ds_lp_b)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_DRL2akPmynC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Entrenamiento"
      ]
    },
    {
      "metadata": {
        "id": "u-n0fZGCskqO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Función auxiliar para la generación de la matriz de confusión"
      ]
    },
    {
      "metadata": {
        "id": "V7msqzlwujrc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_model(text, model):\n",
        "  print(text)\n",
        "  word_list = text_to_wordlist(text)\n",
        "  sequences = tokenizer.texts_to_sequences([word_list])\n",
        "  sequentes_input = list(itertools.chain(*sequences))\n",
        "  sequentes_input =  pad_sequences([sequentes_input], value=0, padding=\"post\", maxlen=windows_size).tolist()\n",
        "  input_a = np.asarray(sequentes_input)\n",
        "  pred = model.predict(input_a, batch_size=None, verbose=0, steps=None)\n",
        "  print(pred)\n",
        "  predicted_class = np.argmax(pred)\n",
        "  print(labels[predicted_class])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJB1rHgttfnM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def confusion_matrix(model, x, y):\n",
        "  prediction = model.predict(x, batch_size=None, verbose=0, steps=None)\n",
        "  labels=['none','mild','moderate','moderately severe', 'severe']\n",
        "\n",
        "  max_prediction = np.argmax(prediction, axis=1)\n",
        "  max_actual = np.argmax(y, axis=1)\n",
        "\n",
        "  y_pred = pd.Categorical.from_codes(max_prediction, labels)\n",
        "  y_actu = pd.Categorical.from_codes(max_actual, labels)\n",
        "\n",
        "  return pd.crosstab(y_actu, y_pred)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fEabb04LPU5K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Modelo 1"
      ]
    },
    {
      "metadata": {
        "id": "vpOJgqqyHbIq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El primer modelo utiliza el modelo pre entrenado GLObalVEctor que consiste en vectores de 100 elementos que caracterizan para palabra del modelo"
      ]
    },
    {
      "metadata": {
        "id": "UCEs0ofss7LE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cargamos los embeddings del modelo glove"
      ]
    },
    {
      "metadata": {
        "id": "8ghzHW1-BerH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/drive/My Drive/Colab Notebooks/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mInBpIv8tNcy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Función que genera la matriz de embedding que se utilizará en el entrenamiento del modelo"
      ]
    },
    {
      "metadata": {
        "id": "4S1m8ubOBmQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fill_embedding_matrix(tokenizer):\n",
        "  vocab_size = len(tokenizer.word_index)\n",
        "  embedding_matrix = np.zeros((vocab_size+1, 100))\n",
        "  for word, i in tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:        \n",
        "      embedding_matrix[i] = embedding_vector\n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pFVzrJXvtW3e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generamos la matriz para el tokenizer utilizado para generar el dataset de entrenamiento"
      ]
    },
    {
      "metadata": {
        "id": "sfVGBc3qo3kj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_index)\n",
        "embedding_matrix_lp = fill_embedding_matrix(tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TaihTt1Ati7Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Preparamos los arrays de entrada al modelo"
      ]
    },
    {
      "metadata": {
        "id": "I1vrHZcx9Su4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "train_a = np.stack(train_lp['t_answer'], axis=0)\n",
        "dev_a = np.stack(dev_lp['t_answer'], axis=0)\n",
        "train_y = np.stack(train_lp['cat_level'], axis=0)\n",
        "dev_y = np.stack(dev_lp['cat_level'], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9_t5O-vtpgU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verificamos las dimensiones de las entradas del modelo"
      ]
    },
    {
      "metadata": {
        "id": "IgEMjMqasT61",
        "colab_type": "code",
        "outputId": "384c9dc3-c036-4494-eb71-0c2588a541bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print(embedding_matrix_lp.shape)\n",
        "print(vocab_size)\n",
        "print(windows_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7374, 100)\n",
            "7373\n",
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mKKJvSqltvrG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Definición del modelo"
      ]
    },
    {
      "metadata": {
        "id": "dx4I9Ti7t2Ru",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generamos un modelo de embedding con LSTM, dos capas densas intermedias y una capa de salida softmax"
      ]
    },
    {
      "metadata": {
        "id": "A7JoZ_JurmNT",
        "colab_type": "code",
        "outputId": "0194e7b5-e922-4e7f-960d-1ebfc74d6c2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "cell_type": "code",
      "source": [
        "answer_inp = Input(shape=(windows_size, ))\n",
        "embedding_size_glove = 100\n",
        "answer_emb1 = Embedding(vocab_size+1, embedding_size_glove, weights=[embedding_matrix_lp], input_length=windows_size, trainable=False)(answer_inp)\n",
        "\n",
        "bt = BatchNormalization()(answer_emb1)\n",
        "lstm = LSTM(embedding_size_glove, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)(bt)\n",
        "\n",
        "dense1 = Dense(units=256, activation=\"relu\")(lstm)\n",
        "dense2 = Dense(units=256, activation=\"relu\")(dense1)\n",
        "\n",
        "flatten = Flatten()(dense2)\n",
        "\n",
        "out = Dense(5,  activation='softmax')(flatten)\n",
        "\n",
        "model = Model(inputs=[answer_inp], outputs=[out])\n",
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 10, 100)           737400    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 10, 100)           400       \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 10, 100)           80400     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10, 256)           25856     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10, 256)           65792     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2560)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 5)                 12805     \n",
            "=================================================================\n",
            "Total params: 922,653\n",
            "Trainable params: 185,053\n",
            "Non-trainable params: 737,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-SXB8trcuJqO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Entrenamiento del modelo"
      ]
    },
    {
      "metadata": {
        "id": "sgLgIZBDrkJu",
        "colab_type": "code",
        "outputId": "7fbb4be5-22a8-4f32-e53b-6938e75343f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "model_glove_hist = model.fit([train_a], train_y, \\\n",
        "        validation_data=([dev_a], dev_y), \\\n",
        "        epochs=30, batch_size=64, shuffle=True, \\\n",
        "         callbacks=[early_stopping])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 99969 samples, validate on 19993 samples\n",
            "Epoch 1/30\n",
            "99969/99969 [==============================] - 72s 717us/step - loss: 1.4449 - acc: 0.3791 - val_loss: 1.3283 - val_acc: 0.4466\n",
            "Epoch 2/30\n",
            "99969/99969 [==============================] - 71s 708us/step - loss: 1.2631 - acc: 0.4750 - val_loss: 1.0937 - val_acc: 0.5620\n",
            "Epoch 3/30\n",
            "99969/99969 [==============================] - 70s 704us/step - loss: 1.0998 - acc: 0.5540 - val_loss: 0.9363 - val_acc: 0.6356\n",
            "Epoch 4/30\n",
            "99969/99969 [==============================] - 71s 708us/step - loss: 0.9932 - acc: 0.6039 - val_loss: 0.8077 - val_acc: 0.6895\n",
            "Epoch 5/30\n",
            "99969/99969 [==============================] - 70s 704us/step - loss: 0.9195 - acc: 0.6365 - val_loss: 0.7255 - val_acc: 0.7274\n",
            "Epoch 6/30\n",
            "99969/99969 [==============================] - 70s 704us/step - loss: 0.8524 - acc: 0.6660 - val_loss: 0.6700 - val_acc: 0.7505\n",
            "Epoch 7/30\n",
            "99969/99969 [==============================] - 70s 703us/step - loss: 0.8001 - acc: 0.6879 - val_loss: 0.5919 - val_acc: 0.7814\n",
            "Epoch 8/30\n",
            "99969/99969 [==============================] - 70s 703us/step - loss: 0.7542 - acc: 0.7083 - val_loss: 0.5528 - val_acc: 0.8014\n",
            "Epoch 9/30\n",
            "99969/99969 [==============================] - 70s 702us/step - loss: 0.7262 - acc: 0.7198 - val_loss: 0.5035 - val_acc: 0.8187\n",
            "Epoch 10/30\n",
            "99969/99969 [==============================] - 71s 706us/step - loss: 0.6885 - acc: 0.7357 - val_loss: 0.4687 - val_acc: 0.8346\n",
            "Epoch 11/30\n",
            "99969/99969 [==============================] - 71s 705us/step - loss: 0.6583 - acc: 0.7482 - val_loss: 0.4488 - val_acc: 0.8425\n",
            "Epoch 12/30\n",
            "99969/99969 [==============================] - 70s 703us/step - loss: 0.6273 - acc: 0.7601 - val_loss: 0.4140 - val_acc: 0.8561\n",
            "Epoch 13/30\n",
            "99969/99969 [==============================] - 70s 701us/step - loss: 0.6139 - acc: 0.7669 - val_loss: 0.3900 - val_acc: 0.8630\n",
            "Epoch 14/30\n",
            "99969/99969 [==============================] - 70s 701us/step - loss: 0.5933 - acc: 0.7743 - val_loss: 0.3713 - val_acc: 0.8722\n",
            "Epoch 15/30\n",
            "99969/99969 [==============================] - 70s 705us/step - loss: 0.5763 - acc: 0.7815 - val_loss: 0.3413 - val_acc: 0.8834\n",
            "Epoch 16/30\n",
            "99969/99969 [==============================] - 70s 702us/step - loss: 0.5476 - acc: 0.7937 - val_loss: 0.3252 - val_acc: 0.8910\n",
            "Epoch 17/30\n",
            "99969/99969 [==============================] - 70s 703us/step - loss: 0.5315 - acc: 0.8002 - val_loss: 0.3110 - val_acc: 0.8925\n",
            "Epoch 18/30\n",
            "99969/99969 [==============================] - 70s 702us/step - loss: 0.5198 - acc: 0.8059 - val_loss: 0.2913 - val_acc: 0.9006\n",
            "Epoch 19/30\n",
            "99969/99969 [==============================] - 70s 704us/step - loss: 0.5036 - acc: 0.8118 - val_loss: 0.2784 - val_acc: 0.9073\n",
            "Epoch 20/30\n",
            "99969/99969 [==============================] - 70s 704us/step - loss: 0.4944 - acc: 0.8165 - val_loss: 0.2779 - val_acc: 0.9055\n",
            "Epoch 21/30\n",
            "99969/99969 [==============================] - 70s 705us/step - loss: 0.4791 - acc: 0.8208 - val_loss: 0.2706 - val_acc: 0.9099\n",
            "Epoch 22/30\n",
            "99969/99969 [==============================] - 70s 702us/step - loss: 0.4703 - acc: 0.8245 - val_loss: 0.2493 - val_acc: 0.9153\n",
            "Epoch 23/30\n",
            "99969/99969 [==============================] - 70s 700us/step - loss: 0.4600 - acc: 0.8295 - val_loss: 0.2344 - val_acc: 0.9217\n",
            "Epoch 24/30\n",
            "99969/99969 [==============================] - 70s 705us/step - loss: 0.4452 - acc: 0.8351 - val_loss: 0.2208 - val_acc: 0.9279\n",
            "Epoch 25/30\n",
            "99969/99969 [==============================] - 70s 702us/step - loss: 0.4341 - acc: 0.8392 - val_loss: 0.2139 - val_acc: 0.9310\n",
            "Epoch 26/30\n",
            "99969/99969 [==============================] - 70s 704us/step - loss: 0.4232 - acc: 0.8441 - val_loss: 0.2038 - val_acc: 0.9317\n",
            "Epoch 27/30\n",
            "99969/99969 [==============================] - 70s 701us/step - loss: 0.4169 - acc: 0.8454 - val_loss: 0.2006 - val_acc: 0.9325\n",
            "Epoch 28/30\n",
            "99969/99969 [==============================] - 70s 703us/step - loss: 0.4057 - acc: 0.8496 - val_loss: 0.2018 - val_acc: 0.9317\n",
            "Epoch 29/30\n",
            "99969/99969 [==============================] - 70s 700us/step - loss: 0.4001 - acc: 0.8524 - val_loss: 0.2044 - val_acc: 0.9317\n",
            "Epoch 30/30\n",
            "99969/99969 [==============================] - 70s 700us/step - loss: 0.3961 - acc: 0.8542 - val_loss: 0.1844 - val_acc: 0.9390\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mtQWmuojuS1l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Revisión de la evolución de las funciones de pérdida y la precisión del modelo"
      ]
    },
    {
      "metadata": {
        "id": "I7PAI9VOuaXW",
        "colab_type": "code",
        "outputId": "c9cbbb33-706b-41b4-e51e-bd8e79532e84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        }
      },
      "cell_type": "code",
      "source": [
        "plot_loss(model_glove_hist)\n",
        "plot_acc(model_glove_hist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fea5343c358>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fea33ade160>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "wi8aWyeuuPHO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Generación de la matriz de confusión para los datos de prueba"
      ]
    },
    {
      "metadata": {
        "id": "bX8NnL6xuPtf",
        "colab_type": "code",
        "outputId": "21f2892e-598b-40b4-8159-2f2d5959d576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "test_a = np.stack(test_lp['t_answer'], axis=0)\n",
        "test_y = np.stack(test_lp['cat_level'], axis=0)\n",
        "df_confusion = confusion_matrix(model, test_a, test_y)\n",
        "df_confusion"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>none</th>\n",
              "      <th>mild</th>\n",
              "      <th>moderate</th>\n",
              "      <th>moderately severe</th>\n",
              "      <th>severe</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>none</th>\n",
              "      <td>3261</td>\n",
              "      <td>149</td>\n",
              "      <td>118</td>\n",
              "      <td>38</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mild</th>\n",
              "      <td>70</td>\n",
              "      <td>7424</td>\n",
              "      <td>199</td>\n",
              "      <td>79</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moderate</th>\n",
              "      <td>43</td>\n",
              "      <td>120</td>\n",
              "      <td>5912</td>\n",
              "      <td>56</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moderately severe</th>\n",
              "      <td>23</td>\n",
              "      <td>55</td>\n",
              "      <td>86</td>\n",
              "      <td>2665</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>severe</th>\n",
              "      <td>21</td>\n",
              "      <td>61</td>\n",
              "      <td>61</td>\n",
              "      <td>35</td>\n",
              "      <td>2243</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0              none  mild  moderate  moderately severe  severe\n",
              "row_0                                                             \n",
              "none               3261   149       118                 38      27\n",
              "mild                 70  7424       199                 79      60\n",
              "moderate             43   120      5912                 56      29\n",
              "moderately severe    23    55        86               2665      14\n",
              "severe               21    61        61                 35    2243"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "metadata": {
        "id": "6xt7iRZ2O7g8",
        "colab_type": "code",
        "outputId": "f29fb9b9-5801-441a-fb0b-830147061c00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "score = model.evaluate(test_a, test_y, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.18223804577849545\n",
            "Test accuracy: 0.9411790450347937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Ft_-EDBRrfO",
        "colab_type": "code",
        "outputId": "e9e03ad5-c672-44b4-d490-58588e869358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "sen = \"All is going right with the party, I'm happy to know new people\"\n",
        "test_model(sen, model)\n",
        "sen = \"I want an ice cream and have some fries for lunch\"\n",
        "test_model(sen, model)\n",
        "sen = \"I'm afraid of lose my work, I don't have any money\"\n",
        "test_model(sen, model)\n",
        "sen = \"I'm worried about my future, I'm afroid of it\"\n",
        "test_model(sen, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00161312 0.00390227 0.9809186  0.00412826 0.00943785]]\n",
            "moderate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qwgfCRtpQBXY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
        "train_b_a = np.stack(train_lp_b['t_answer'], axis=0)\n",
        "dev_b_a = np.stack(dev_lp_b['t_answer'], axis=0)\n",
        "train_b_y = np.stack(train_lp_b['cat_level'], axis=0)\n",
        "dev_b_y = np.stack(dev_lp_b['cat_level'], axis=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pa-Vng-IQScA",
        "colab_type": "code",
        "outputId": "e553f85f-4d5f-447e-e4e7-c4ff18a31304",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "model_glove_hist = model.fit([train_b_a], train_b_y, \\\n",
        "        validation_data=([dev_b_a], dev_y), \\\n",
        "        epochs=30, batch_size=64, shuffle=True, \\\n",
        "         callbacks=[early_stopping])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 66771 samples, validate on 13354 samples\n",
            "Epoch 1/30\n",
            "66771/66771 [==============================] - 48s 725us/step - loss: 0.3815 - acc: 0.8598 - val_loss: 0.0857 - val_acc: 0.9747\n",
            "Epoch 2/30\n",
            "66771/66771 [==============================] - 48s 714us/step - loss: 0.3396 - acc: 0.8775 - val_loss: 0.0764 - val_acc: 0.9778\n",
            "Epoch 3/30\n",
            "66771/66771 [==============================] - 47s 711us/step - loss: 0.3232 - acc: 0.8826 - val_loss: 0.0788 - val_acc: 0.9778\n",
            "Epoch 4/30\n",
            "66771/66771 [==============================] - 47s 709us/step - loss: 0.3041 - acc: 0.8911 - val_loss: 0.0714 - val_acc: 0.9798\n",
            "Epoch 5/30\n",
            "66771/66771 [==============================] - 47s 708us/step - loss: 0.2924 - acc: 0.8937 - val_loss: 0.0711 - val_acc: 0.9793\n",
            "Epoch 6/30\n",
            "66771/66771 [==============================] - 48s 713us/step - loss: 0.2803 - acc: 0.8997 - val_loss: 0.0675 - val_acc: 0.9802\n",
            "Epoch 7/30\n",
            "66771/66771 [==============================] - 48s 714us/step - loss: 0.2699 - acc: 0.9033 - val_loss: 0.0649 - val_acc: 0.9798\n",
            "Epoch 8/30\n",
            "66771/66771 [==============================] - 47s 705us/step - loss: 0.2629 - acc: 0.9041 - val_loss: 0.0661 - val_acc: 0.9803\n",
            "Epoch 9/30\n",
            "66771/66771 [==============================] - 47s 703us/step - loss: 0.2525 - acc: 0.9106 - val_loss: 0.0593 - val_acc: 0.9823\n",
            "Epoch 10/30\n",
            "66771/66771 [==============================] - 47s 702us/step - loss: 0.2488 - acc: 0.9101 - val_loss: 0.0625 - val_acc: 0.9811\n",
            "Epoch 11/30\n",
            "66771/66771 [==============================] - 47s 702us/step - loss: 0.2401 - acc: 0.9135 - val_loss: 0.0629 - val_acc: 0.9805\n",
            "Epoch 12/30\n",
            "66771/66771 [==============================] - 47s 705us/step - loss: 0.2341 - acc: 0.9156 - val_loss: 0.0623 - val_acc: 0.9792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a4XJnc8eVTzh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_loss(model_glove_hist)\n",
        "plot_acc(model_glove_hist)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wcYl9fPiS1EE",
        "colab_type": "code",
        "outputId": "68a031d9-2535-4aac-bd14-003496d0b41d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "test_a = np.stack(test_lp_b['t_answer'], axis=0)\n",
        "test_y = np.stack(test_lp_b['cat_level'], axis=0)\n",
        "df_confusion = confusion_matrix(model, test_a, test_y)\n",
        "df_confusion"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>none</th>\n",
              "      <th>mild</th>\n",
              "      <th>moderate</th>\n",
              "      <th>moderately severe</th>\n",
              "      <th>severe</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>none</th>\n",
              "      <td>3506</td>\n",
              "      <td>29</td>\n",
              "      <td>23</td>\n",
              "      <td>13</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mild</th>\n",
              "      <td>6</td>\n",
              "      <td>2851</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moderate</th>\n",
              "      <td>11</td>\n",
              "      <td>14</td>\n",
              "      <td>3452</td>\n",
              "      <td>6</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>moderately severe</th>\n",
              "      <td>5</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "      <td>2789</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>severe</th>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>2386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0              none  mild  moderate  moderately severe  severe\n",
              "row_0                                                             \n",
              "none               3506    29        23                 13      22\n",
              "mild                  6  2851        19                 11      15\n",
              "moderate             11    14      3452                  6      19\n",
              "moderately severe     5    17        20               2789      12\n",
              "severe                7    10        10                  8    2386"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "metadata": {
        "id": "aV48sjrVohcM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Probamos el modelo con frases de diferente contenido"
      ]
    },
    {
      "metadata": {
        "id": "Hw8JQFxeTB5Z",
        "colab_type": "code",
        "outputId": "37b05a2b-bb0a-4961-b3b3-27e62891efdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "sen = \"All is going right with the party, I'm happy to know new people\"\n",
        "test_model(sen, model)\n",
        "sen = \"I want an ice cream and have some fries for lunch\"\n",
        "test_model(sen, model)\n",
        "sen = \"I'm afraid of lose my work, I don't have any money\"\n",
        "test_model(sen, model)\n",
        "sen = \"I'm worried about my future, I'm afroid of it\"\n",
        "test_model(sen, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All is going right with the party, I'm happy to know new people\n",
            "[[0.96018696 0.02134508 0.01124112 0.00294606 0.0042808 ]]\n",
            "none\n",
            "I want an ice cream and have some fries for lunch\n",
            "[[3.2319360e-08 9.9986196e-01 1.3795303e-04 6.5695623e-08 1.6800131e-08]]\n",
            "mild\n",
            "I'm afraid of lose my work, I don't have any money\n",
            "[[2.4046434e-05 4.6233938e-05 9.9924493e-01 4.6035606e-05 6.3879456e-04]]\n",
            "moderate\n",
            "I'm worried about my future, I'm afroid of it\n",
            "[[0.00102986 0.01314219 0.07584719 0.00878967 0.90119106]]\n",
            "severe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ODtz8kfszH-z"
      },
      "cell_type": "markdown",
      "source": [
        "####Modelo 2"
      ]
    },
    {
      "metadata": {
        "id": "xLsebIKdvhwT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El primer modelo utiliza el modelo pre entrenado GLObalVEctor que consiste en vectores de 100 elementos que caracterizan para palabra del modelo"
      ]
    },
    {
      "metadata": {
        "id": "yajMCYKFvqoR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cargamos el modelo de google news vectors negative mediante el uso de la libreria gensim"
      ]
    },
    {
      "metadata": {
        "id": "IUUw9Xw4tkha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2vec = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/My Drive/Colab Notebooks/GoogleNews-vectors-negative300.bin', binary=True)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cr3LwpZTvps8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Función que genera la matriz de embedding con el tokenizer utilizado para generar el dataset de entrenamiento"
      ]
    },
    {
      "metadata": {
        "id": "JTqHtDfj5YDE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def fill_embedding_matrix_google(vocab_size, tokenizer):  \n",
        "  embedding_matrix = np.zeros((vocab_size+1, 300))  \n",
        "  for word, i in tokenizer.word_index.items():\n",
        "      if word in word2vec.vocab:        \n",
        "          embedding_matrix[i] = word2vec.word_vec(word)        \n",
        "  return embedding_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4sdWyRGF1xJ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix_gg = fill_embedding_matrix_google(vocab_size, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M27NTIVQv4DB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "sFIpGo1s6uc_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 300\n",
        "MAX_SEQUENCE_LENGTH = windows_size\n",
        "num_lstm = np.random.randint(175, 275)\n",
        "num_dense = np.random.randint(100, 150)\n",
        "rate_drop_lstm = 0.15 + np.random.rand() * 0.25\n",
        "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
        "\n",
        "act = 'relu'\n",
        "\n",
        "STAMP = 'lstm_%d_%d_%.2f_%.2f'%(num_lstm, num_dense, rate_drop_lstm, \\\n",
        "        rate_drop_dense)\n",
        "\n",
        "embedding_layer = Embedding(vocab_size+1,\n",
        "        EMBEDDING_DIM,\n",
        "        weights=[embedding_matrix_gg],\n",
        "        input_length=MAX_SEQUENCE_LENGTH,\n",
        "        trainable=False)\n",
        "\n",
        "lstm_layer = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)\n",
        "\n",
        "answer_inp = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_1 = embedding_layer(answer_inp)\n",
        "x1 = lstm_layer(embedded_sequences_1)\n",
        "\n",
        "merged = x1\n",
        "merged = Dropout(rate_drop_dense)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "merged = Dense(num_dense, activation=act)(merged)\n",
        "merged = Dropout(rate_drop_dense)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "out = Dense(5, activation='softmax')(merged)\n",
        "\n",
        "model_gg_1 = Model(inputs=[answer_inp], outputs=[out])\n",
        "model_gg_1.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fhEze8_Q7as2",
        "colab_type": "code",
        "outputId": "24b51eb7-a942-41e1-8ff4-c620d8ce1341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "bst_model_path = STAMP + '.google.h5'\n",
        "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "model_google_hist = model_gg_1.fit([train_b_a], train_b_y, \\\n",
        "        validation_data=([dev_b_a], dev_b_y), \\\n",
        "        epochs=30, batch_size=64, shuffle=True, \\\n",
        "         callbacks=[early_stopping, model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 66771 samples, validate on 13354 samples\n",
            "Epoch 1/30\n",
            "66771/66771 [==============================] - 47s 701us/step - loss: 0.8070 - acc: 0.6917 - val_loss: 0.6042 - val_acc: 0.7878\n",
            "Epoch 2/30\n",
            "66771/66771 [==============================] - 47s 701us/step - loss: 0.7566 - acc: 0.7145 - val_loss: 0.5508 - val_acc: 0.8140\n",
            "Epoch 3/30\n",
            "66771/66771 [==============================] - 47s 702us/step - loss: 0.7063 - acc: 0.7341 - val_loss: 0.5038 - val_acc: 0.8268\n",
            "Epoch 4/30\n",
            "66771/66771 [==============================] - 47s 701us/step - loss: 0.6659 - acc: 0.7521 - val_loss: 0.4763 - val_acc: 0.8374\n",
            "Epoch 5/30\n",
            "66771/66771 [==============================] - 47s 701us/step - loss: 0.6281 - acc: 0.7680 - val_loss: 0.4172 - val_acc: 0.8606\n",
            "Epoch 6/30\n",
            "66771/66771 [==============================] - 47s 702us/step - loss: 0.5933 - acc: 0.7810 - val_loss: 0.3659 - val_acc: 0.8750\n",
            "Epoch 7/30\n",
            "66771/66771 [==============================] - 47s 699us/step - loss: 0.5652 - acc: 0.7910 - val_loss: 0.3493 - val_acc: 0.8916\n",
            "Epoch 8/30\n",
            "66771/66771 [==============================] - 47s 696us/step - loss: 0.5384 - acc: 0.8024 - val_loss: 0.3172 - val_acc: 0.8955\n",
            "Epoch 9/30\n",
            "66771/66771 [==============================] - 47s 708us/step - loss: 0.5161 - acc: 0.8110 - val_loss: 0.2955 - val_acc: 0.9037\n",
            "Epoch 10/30\n",
            "66771/66771 [==============================] - 47s 704us/step - loss: 0.4933 - acc: 0.8213 - val_loss: 0.2772 - val_acc: 0.9088\n",
            "Epoch 11/30\n",
            "66771/66771 [==============================] - 47s 697us/step - loss: 0.4757 - acc: 0.8266 - val_loss: 0.2538 - val_acc: 0.9179\n",
            "Epoch 12/30\n",
            "66771/66771 [==============================] - 47s 700us/step - loss: 0.4580 - acc: 0.8364 - val_loss: 0.2367 - val_acc: 0.9235\n",
            "Epoch 13/30\n",
            "66771/66771 [==============================] - 47s 697us/step - loss: 0.4399 - acc: 0.8416 - val_loss: 0.2166 - val_acc: 0.9334\n",
            "Epoch 14/30\n",
            "66771/66771 [==============================] - 47s 699us/step - loss: 0.4244 - acc: 0.8482 - val_loss: 0.2113 - val_acc: 0.9317\n",
            "Epoch 15/30\n",
            "66771/66771 [==============================] - 46s 696us/step - loss: 0.4128 - acc: 0.8516 - val_loss: 0.2082 - val_acc: 0.9315\n",
            "Epoch 16/30\n",
            "66771/66771 [==============================] - 47s 698us/step - loss: 0.3955 - acc: 0.8583 - val_loss: 0.1866 - val_acc: 0.9402\n",
            "Epoch 17/30\n",
            "66771/66771 [==============================] - 47s 697us/step - loss: 0.3897 - acc: 0.8621 - val_loss: 0.1859 - val_acc: 0.9392\n",
            "Epoch 18/30\n",
            "66771/66771 [==============================] - 46s 694us/step - loss: 0.3799 - acc: 0.8637 - val_loss: 0.1756 - val_acc: 0.9452\n",
            "Epoch 19/30\n",
            "66771/66771 [==============================] - 46s 696us/step - loss: 0.3704 - acc: 0.8680 - val_loss: 0.1720 - val_acc: 0.9447\n",
            "Epoch 20/30\n",
            "66771/66771 [==============================] - 46s 696us/step - loss: 0.3607 - acc: 0.8718 - val_loss: 0.1540 - val_acc: 0.9526\n",
            "Epoch 21/30\n",
            "66771/66771 [==============================] - 46s 693us/step - loss: 0.3539 - acc: 0.8747 - val_loss: 0.1485 - val_acc: 0.9542\n",
            "Epoch 22/30\n",
            "66771/66771 [==============================] - 46s 696us/step - loss: 0.3470 - acc: 0.8773 - val_loss: 0.1413 - val_acc: 0.9559\n",
            "Epoch 23/30\n",
            "66771/66771 [==============================] - 47s 698us/step - loss: 0.3404 - acc: 0.8799 - val_loss: 0.1341 - val_acc: 0.9572\n",
            "Epoch 24/30\n",
            "66771/66771 [==============================] - 46s 696us/step - loss: 0.3336 - acc: 0.8822 - val_loss: 0.1297 - val_acc: 0.9600\n",
            "Epoch 25/30\n",
            "66771/66771 [==============================] - 46s 695us/step - loss: 0.3240 - acc: 0.8864 - val_loss: 0.1303 - val_acc: 0.9585\n",
            "Epoch 26/30\n",
            "66771/66771 [==============================] - 46s 694us/step - loss: 0.3165 - acc: 0.8885 - val_loss: 0.1183 - val_acc: 0.9636\n",
            "Epoch 27/30\n",
            "66771/66771 [==============================] - 46s 695us/step - loss: 0.3121 - acc: 0.8911 - val_loss: 0.1159 - val_acc: 0.9628\n",
            "Epoch 28/30\n",
            "66771/66771 [==============================] - 47s 698us/step - loss: 0.3097 - acc: 0.8919 - val_loss: 0.1125 - val_acc: 0.9641\n",
            "Epoch 29/30\n",
            "66771/66771 [==============================] - 47s 700us/step - loss: 0.3028 - acc: 0.8935 - val_loss: 0.1089 - val_acc: 0.9653\n",
            "Epoch 30/30\n",
            "66771/66771 [==============================] - 47s 698us/step - loss: 0.2990 - acc: 0.8960 - val_loss: 0.1094 - val_acc: 0.9669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EgK6JcQIvw5Z",
        "colab_type": "code",
        "outputId": "fa0b8cc1-e9cf-4261-e2fc-49693790f49d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "sen = \"All is going right with the party, I'm happy to know new people\"\n",
        "test_model(sen, model_gg_1)\n",
        "sen = \"I want an ice cream and have some fries for lunch\"\n",
        "test_model(sen, model_gg_1)\n",
        "sen = \"I'm afraid of lose my work, I don't have any money\"\n",
        "test_model(sen, model_gg_1)\n",
        "sen = \"I'm worried about my future, I'm afroid of it\"\n",
        "test_model(sen, model_gg_1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All is going right with the party, I'm happy to know new people\n",
            "[[9.8742074e-01 1.1647036e-02 5.2166346e-04 3.8331844e-05 3.7235199e-04]]\n",
            "none\n",
            "I want an ice cream and have some fries for lunch\n",
            "[[1.14469542e-04 9.86975670e-01 4.57844348e-04 4.68699545e-05\n",
            "  1.24051515e-02]]\n",
            "mild\n",
            "I'm afraid of lose my work, I don't have any money\n",
            "[[1.2398426e-06 8.8048782e-06 3.1105026e-06 1.8488665e-05 9.9996841e-01]]\n",
            "severe\n",
            "I'm worried about my future, I'm afroid of it\n",
            "[[0.0033872  0.01970866 0.01164115 0.16561747 0.79964554]]\n",
            "severe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wDYXdwFDwMpn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Modelo 3"
      ]
    },
    {
      "metadata": {
        "id": "7S9RYBzc8iva",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "MAX_SEQUENCE_LENGTH = windows_size\n",
        "\n",
        "num_lstm = np.random.randint(175, 275)\n",
        "num_dense = np.random.randint(100, 150)\n",
        "rate_drop_lstm = 0.15 + np.random.rand() * 0.25\n",
        "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
        "\n",
        "act = 'relu'\n",
        "\n",
        "STAMP = 'lstm_%d_%d_%.2f_%.2f'%(num_lstm, num_dense, rate_drop_lstm, \\\n",
        "        rate_drop_dense)\n",
        "\n",
        "embedding_layer = Embedding(vocab_size+1,\n",
        "        EMBEDDING_DIM,\n",
        "        weights=[embedding_matrix_lp],\n",
        "        input_length=MAX_SEQUENCE_LENGTH,\n",
        "        trainable=False)\n",
        "\n",
        "lstm_layer1 = LSTM(num_lstm, return_sequences= True, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm) \n",
        "lstm_layer2 = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)\n",
        "\n",
        "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
        "x1 = lstm_layer1(embedded_sequences_1)\n",
        "merged = lstm_layer2(x1)\n",
        "\n",
        "merged = Dropout(rate_drop_dense)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "preds = Dense(5, activation='softmax')(merged)\n",
        "\n",
        "model_gg_2 = Model(inputs=[sequence_1_input], \\\n",
        "        outputs=preds)\n",
        "\n",
        "model_gg_2.compile(loss='categorical_crossentropy',\n",
        "        optimizer='nadam',\n",
        "        metrics=['acc'])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xm0kuf9kHC95",
        "colab_type": "code",
        "outputId": "247fcef5-80af-4a37-dfc3-77bc41e32f9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1054
        }
      },
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
        "bst_model_path = STAMP + '.google2.h5'\n",
        "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "model_google_hist = model_gg_2.fit([train_b_a], train_b_y, \\\n",
        "        validation_data=([dev_b_a], dev_b_y), \\\n",
        "        epochs=30, batch_size=64, shuffle=True, \\\n",
        "         callbacks=[early_stopping, model_checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 66771 samples, validate on 13354 samples\n",
            "Epoch 1/30\n",
            "66771/66771 [==============================] - 85s 1ms/step - loss: 1.6396 - acc: 0.2600 - val_loss: 1.6054 - val_acc: 0.2750\n",
            "Epoch 2/30\n",
            "66771/66771 [==============================] - 81s 1ms/step - loss: 1.5317 - acc: 0.3198 - val_loss: 1.4543 - val_acc: 0.3713\n",
            "Epoch 3/30\n",
            "66771/66771 [==============================] - 82s 1ms/step - loss: 1.4272 - acc: 0.3909 - val_loss: 1.3158 - val_acc: 0.4516\n",
            "Epoch 4/30\n",
            "66771/66771 [==============================] - 81s 1ms/step - loss: 1.2821 - acc: 0.4732 - val_loss: 1.1156 - val_acc: 0.5545\n",
            "Epoch 5/30\n",
            "66771/66771 [==============================] - 81s 1ms/step - loss: 1.1300 - acc: 0.5519 - val_loss: 0.9170 - val_acc: 0.6629\n",
            "Epoch 6/30\n",
            "66771/66771 [==============================] - 81s 1ms/step - loss: 1.0146 - acc: 0.6033 - val_loss: 0.7782 - val_acc: 0.7045\n",
            "Epoch 7/30\n",
            "66771/66771 [==============================] - 81s 1ms/step - loss: 0.9181 - acc: 0.6448 - val_loss: 0.6718 - val_acc: 0.7569\n",
            "Epoch 8/30\n",
            "66771/66771 [==============================] - 80s 1ms/step - loss: 0.8489 - acc: 0.6757 - val_loss: 0.5811 - val_acc: 0.7956\n",
            "Epoch 9/30\n",
            "66771/66771 [==============================] - 80s 1ms/step - loss: 0.7973 - acc: 0.6987 - val_loss: 0.5156 - val_acc: 0.8135\n",
            "Epoch 10/30\n",
            "66771/66771 [==============================] - 79s 1ms/step - loss: 0.7515 - acc: 0.7173 - val_loss: 0.4731 - val_acc: 0.8321\n",
            "Epoch 11/30\n",
            "66771/66771 [==============================] - 80s 1ms/step - loss: 0.7189 - acc: 0.7307 - val_loss: 0.4481 - val_acc: 0.8408\n",
            "Epoch 12/30\n",
            "66771/66771 [==============================] - 80s 1ms/step - loss: 0.6834 - acc: 0.7452 - val_loss: 0.4000 - val_acc: 0.8631\n",
            "Epoch 13/30\n",
            "66771/66771 [==============================] - 79s 1ms/step - loss: 0.6622 - acc: 0.7509 - val_loss: 0.3787 - val_acc: 0.8752\n",
            "Epoch 14/30\n",
            "66771/66771 [==============================] - 79s 1ms/step - loss: 0.6351 - acc: 0.7654 - val_loss: 0.3386 - val_acc: 0.8833\n",
            "Epoch 15/30\n",
            "66771/66771 [==============================] - 80s 1ms/step - loss: 0.6150 - acc: 0.7739 - val_loss: 0.3299 - val_acc: 0.8911\n",
            "Epoch 16/30\n",
            "66771/66771 [==============================] - 79s 1ms/step - loss: 0.5974 - acc: 0.7807 - val_loss: 0.3028 - val_acc: 0.8982\n",
            "Epoch 17/30\n",
            "66771/66771 [==============================] - 79s 1ms/step - loss: 0.5856 - acc: 0.7852 - val_loss: 0.2879 - val_acc: 0.9049\n",
            "Epoch 18/30\n",
            "66771/66771 [==============================] - 79s 1ms/step - loss: 0.5735 - acc: 0.7904 - val_loss: 0.2693 - val_acc: 0.9150\n",
            "Epoch 19/30\n",
            "66771/66771 [==============================] - 79s 1ms/step - loss: 0.5566 - acc: 0.7974 - val_loss: 0.2602 - val_acc: 0.9161\n",
            "Epoch 20/30\n",
            "66771/66771 [==============================] - 78s 1ms/step - loss: 0.5469 - acc: 0.8000 - val_loss: 0.2403 - val_acc: 0.9245\n",
            "Epoch 21/30\n",
            "66771/66771 [==============================] - 78s 1ms/step - loss: 0.5335 - acc: 0.8054 - val_loss: 0.2425 - val_acc: 0.9226\n",
            "Epoch 22/30\n",
            "66771/66771 [==============================] - 77s 1ms/step - loss: 0.5234 - acc: 0.8087 - val_loss: 0.2161 - val_acc: 0.9322\n",
            "Epoch 23/30\n",
            "66771/66771 [==============================] - 78s 1ms/step - loss: 0.5194 - acc: 0.8113 - val_loss: 0.2132 - val_acc: 0.9322\n",
            "Epoch 24/30\n",
            "66771/66771 [==============================] - 78s 1ms/step - loss: 0.5084 - acc: 0.8167 - val_loss: 0.2046 - val_acc: 0.9316\n",
            "Epoch 25/30\n",
            "66771/66771 [==============================] - 77s 1ms/step - loss: 0.5067 - acc: 0.8179 - val_loss: 0.1929 - val_acc: 0.9410\n",
            "Epoch 26/30\n",
            "66771/66771 [==============================] - 76s 1ms/step - loss: 0.4970 - acc: 0.8210 - val_loss: 0.2055 - val_acc: 0.9340\n",
            "Epoch 27/30\n",
            "66771/66771 [==============================] - 78s 1ms/step - loss: 0.4879 - acc: 0.8242 - val_loss: 0.1849 - val_acc: 0.9421\n",
            "Epoch 28/30\n",
            "66771/66771 [==============================] - 77s 1ms/step - loss: 0.4815 - acc: 0.8288 - val_loss: 0.1824 - val_acc: 0.9448\n",
            "Epoch 29/30\n",
            "66771/66771 [==============================] - 77s 1ms/step - loss: 0.4727 - acc: 0.8315 - val_loss: 0.1738 - val_acc: 0.9458\n",
            "Epoch 30/30\n",
            "66771/66771 [==============================] - 77s 1ms/step - loss: 0.4681 - acc: 0.8323 - val_loss: 0.1670 - val_acc: 0.9506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qemogdk_PjGG",
        "colab_type": "code",
        "outputId": "ff87aa26-f2bd-4e5d-93c5-d8fe2a4b44ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "sen = \"All is going right with the party, I'm happy to know new people\"\n",
        "test_model(sen, model_gg_2)\n",
        "sen = \"I want an ice cream and have some fries for lunch\"\n",
        "test_model(sen, model_gg_2)\n",
        "sen = \"I'm afraid of lose my work, I don't have any money\"\n",
        "test_model(sen, model_gg_2)\n",
        "sen = \"I'm worried about my future, I'm afroid of it\"\n",
        "test_model(sen, model_gg_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All is going right with the party, I'm happy to know new people\n",
            "[[0.6963605  0.2039925  0.03281944 0.04269654 0.02413098]]\n",
            "none\n",
            "I want an ice cream and have some fries for lunch\n",
            "[[1.0345574e-03 9.2524663e-03 9.8935169e-01 1.8656383e-04 1.7471997e-04]]\n",
            "moderate\n",
            "I'm afraid of lose my work, I don't have any money\n",
            "[[0.30783388 0.00278217 0.01279544 0.01762625 0.65896225]]\n",
            "severe\n",
            "I'm worried about my future, I'm afroid of it\n",
            "[[0.08877082 0.6027601  0.16042632 0.01096619 0.13707654]]\n",
            "mild\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PDGhSyASwS0T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Modelo 4"
      ]
    },
    {
      "metadata": {
        "id": "xWMTIwJwA1x5",
        "colab_type": "code",
        "outputId": "37bdd55f-3a23-470b-be7e-0db32d784269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "num_lstm = np.random.randint(175, 275)\n",
        "num_dense = np.random.randint(100, 150)\n",
        "rate_drop_lstm = 0.15 + np.random.rand() * 0.25\n",
        "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
        "act = 'relu'\n",
        "\n",
        "embedding_layer = Embedding(vocab_size+1,\n",
        "        EMBEDDING_DIM,\n",
        "        weights=[embedding_matrix_lp],\n",
        "        input_length=MAX_SEQUENCE_LENGTH,\n",
        "        trainable=False)\n",
        "lstm_layer = LSTM(num_lstm, dropout=rate_drop_lstm, recurrent_dropout=rate_drop_lstm)\n",
        "\n",
        "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
        "x1 = lstm_layer(embedded_sequences_1)\n",
        "\n",
        "merged = Dropout(rate_drop_dense)(x1)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "merged = Dense(num_dense, activation=act)(merged)\n",
        "merged = Dropout(rate_drop_dense)(merged)\n",
        "merged = BatchNormalization()(merged)\n",
        "\n",
        "preds_1 = Dense(5, activation='softmax')(merged)\n",
        "preds_2 = Dense(1, activation='sigmoid')(merged)\n",
        "\n",
        "model = Model(inputs=[sequence_1_input], \\\n",
        "        outputs=[preds_1, preds_2])\n",
        "\n",
        "model.compile(loss=['categorical_crossentropy', 'mean_squared_error'],\n",
        "        optimizer='nadam', loss_weights=[1., 0.2],\n",
        "        metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           (None, 10)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_11 (Embedding)        (None, 10, 100)      737400      input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_17 (LSTM)                  (None, 265)          387960      embedding_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 265)          0           lstm_17[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 265)          1060        dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 141)          37506       batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 141)          0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 141)          564         dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 5)            710         batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 1)            142         batch_normalization_11[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 1,165,342\n",
            "Trainable params: 427,130\n",
            "Non-trainable params: 738,212\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kwjW1D6WRGHE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_phq_score = train_lp_b['PHQ8_Score'] \n",
        "dev_phq_score = dev_lp_b['PHQ8_Score'] \n",
        "test_phq_score = test_lp_b['PHQ8_Score'] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jmAwkB1oBgHt",
        "colab_type": "code",
        "outputId": "c904c10b-f8a2-44d2-d14f-8ca86ae96778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1074
        }
      },
      "cell_type": "code",
      "source": [
        "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
        "bst_model_path = STAMP + '.twolosses.h5'\n",
        "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "hist = model.fit([train_b_a], [train_b_y, train_phq_score], \\\n",
        "        validation_data=([dev_b_a], [dev_b_y, dev_phq_score]), \\\n",
        "        epochs=30, batch_size=64, shuffle=True, callbacks=[early_stopping])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 66771 samples, validate on 13354 samples\n",
            "Epoch 1/30\n",
            "66771/66771 [==============================] - 51s 767us/step - loss: 19.1457 - dense_16_loss: 1.6423 - dense_17_loss: 87.5170 - dense_16_acc: 0.2572 - dense_17_acc: 0.0237 - val_loss: 19.0494 - val_dense_16_loss: 1.5619 - val_dense_17_loss: 87.4372 - val_dense_16_acc: 0.2885 - val_dense_17_acc: 0.0207\n",
            "Epoch 2/30\n",
            "66771/66771 [==============================] - 49s 729us/step - loss: 18.9756 - dense_16_loss: 1.5501 - dense_17_loss: 87.1278 - dense_16_acc: 0.3012 - dense_17_acc: 0.0198 - val_loss: 18.9897 - val_dense_16_loss: 1.5024 - val_dense_17_loss: 87.4365 - val_dense_16_acc: 0.3388 - val_dense_17_acc: 0.0207\n",
            "Epoch 3/30\n",
            "66771/66771 [==============================] - 48s 718us/step - loss: 18.9106 - dense_16_loss: 1.4853 - dense_17_loss: 87.1265 - dense_16_acc: 0.3526 - dense_17_acc: 0.0198 - val_loss: 18.8752 - val_dense_16_loss: 1.3879 - val_dense_17_loss: 87.4364 - val_dense_16_acc: 0.4206 - val_dense_17_acc: 0.0207\n",
            "Epoch 4/30\n",
            "66771/66771 [==============================] - 49s 734us/step - loss: 18.8163 - dense_16_loss: 1.3910 - dense_17_loss: 87.1262 - dense_16_acc: 0.4130 - dense_17_acc: 0.0198 - val_loss: 18.7390 - val_dense_16_loss: 1.2517 - val_dense_17_loss: 87.4364 - val_dense_16_acc: 0.4955 - val_dense_17_acc: 0.0207\n",
            "Epoch 5/30\n",
            "66771/66771 [==============================] - 48s 713us/step - loss: 18.6947 - dense_16_loss: 1.2695 - dense_17_loss: 87.1261 - dense_16_acc: 0.4819 - dense_17_acc: 0.0198 - val_loss: 18.5712 - val_dense_16_loss: 1.0839 - val_dense_17_loss: 87.4363 - val_dense_16_acc: 0.5788 - val_dense_17_acc: 0.0207\n",
            "Epoch 6/30\n",
            "66771/66771 [==============================] - 47s 703us/step - loss: 18.5704 - dense_16_loss: 1.1452 - dense_17_loss: 87.1260 - dense_16_acc: 0.5461 - dense_17_acc: 0.0198 - val_loss: 18.3976 - val_dense_16_loss: 0.9103 - val_dense_17_loss: 87.4362 - val_dense_16_acc: 0.6551 - val_dense_17_acc: 0.0207\n",
            "Epoch 7/30\n",
            "66771/66771 [==============================] - 48s 715us/step - loss: 18.4619 - dense_16_loss: 1.0368 - dense_17_loss: 87.1259 - dense_16_acc: 0.5970 - dense_17_acc: 0.0198 - val_loss: 18.2712 - val_dense_16_loss: 0.7840 - val_dense_17_loss: 87.4362 - val_dense_16_acc: 0.7187 - val_dense_17_acc: 0.0207\n",
            "Epoch 8/30\n",
            "66771/66771 [==============================] - 47s 703us/step - loss: 18.3752 - dense_16_loss: 0.9500 - dense_17_loss: 87.1258 - dense_16_acc: 0.6366 - dense_17_acc: 0.0198 - val_loss: 18.1574 - val_dense_16_loss: 0.6702 - val_dense_17_loss: 87.4361 - val_dense_16_acc: 0.7619 - val_dense_17_acc: 0.0207\n",
            "Epoch 9/30\n",
            "66771/66771 [==============================] - 47s 702us/step - loss: 18.3050 - dense_16_loss: 0.8798 - dense_17_loss: 87.1258 - dense_16_acc: 0.6682 - dense_17_acc: 0.0198 - val_loss: 18.0858 - val_dense_16_loss: 0.5986 - val_dense_17_loss: 87.4361 - val_dense_16_acc: 0.7882 - val_dense_17_acc: 0.0207\n",
            "Epoch 10/30\n",
            "66771/66771 [==============================] - 47s 702us/step - loss: 18.2494 - dense_16_loss: 0.8243 - dense_17_loss: 87.1257 - dense_16_acc: 0.6921 - dense_17_acc: 0.0198 - val_loss: 18.0270 - val_dense_16_loss: 0.5398 - val_dense_17_loss: 87.4361 - val_dense_16_acc: 0.8150 - val_dense_17_acc: 0.0207\n",
            "Epoch 11/30\n",
            "66771/66771 [==============================] - 48s 715us/step - loss: 18.2060 - dense_16_loss: 0.7808 - dense_17_loss: 87.1256 - dense_16_acc: 0.7087 - dense_17_acc: 0.0198 - val_loss: 17.9639 - val_dense_16_loss: 0.4766 - val_dense_17_loss: 87.4361 - val_dense_16_acc: 0.8341 - val_dense_17_acc: 0.0207\n",
            "Epoch 12/30\n",
            "66771/66771 [==============================] - 47s 699us/step - loss: 18.1796 - dense_16_loss: 0.7545 - dense_17_loss: 87.1256 - dense_16_acc: 0.7218 - dense_17_acc: 0.0198 - val_loss: 17.9436 - val_dense_16_loss: 0.4564 - val_dense_17_loss: 87.4361 - val_dense_16_acc: 0.8430 - val_dense_17_acc: 0.0207\n",
            "Epoch 13/30\n",
            "66771/66771 [==============================] - 48s 712us/step - loss: 18.1474 - dense_16_loss: 0.7223 - dense_17_loss: 87.1254 - dense_16_acc: 0.7336 - dense_17_acc: 0.0199 - val_loss: 17.9107 - val_dense_16_loss: 0.4239 - val_dense_17_loss: 87.4337 - val_dense_16_acc: 0.8548 - val_dense_17_acc: 0.0208\n",
            "Epoch 14/30\n",
            "66771/66771 [==============================] - 46s 690us/step - loss: 18.1191 - dense_16_loss: 0.6981 - dense_17_loss: 87.1049 - dense_16_acc: 0.7435 - dense_17_acc: 0.0573 - val_loss: 17.8781 - val_dense_16_loss: 0.4070 - val_dense_17_loss: 87.3554 - val_dense_16_acc: 0.8633 - val_dense_17_acc: 0.0944\n",
            "Epoch 15/30\n",
            "66771/66771 [==============================] - 47s 697us/step - loss: 18.1052 - dense_16_loss: 0.6859 - dense_17_loss: 87.0962 - dense_16_acc: 0.7494 - dense_17_acc: 0.0659 - val_loss: 17.8534 - val_dense_16_loss: 0.3810 - val_dense_17_loss: 87.3622 - val_dense_16_acc: 0.8735 - val_dense_17_acc: 0.0872\n",
            "Epoch 16/30\n",
            "66771/66771 [==============================] - 47s 703us/step - loss: 18.0874 - dense_16_loss: 0.6687 - dense_17_loss: 87.0934 - dense_16_acc: 0.7569 - dense_17_acc: 0.0679 - val_loss: 17.8474 - val_dense_16_loss: 0.3739 - val_dense_17_loss: 87.3674 - val_dense_16_acc: 0.8780 - val_dense_17_acc: 0.0814\n",
            "Epoch 17/30\n",
            "66771/66771 [==============================] - 48s 713us/step - loss: 18.0711 - dense_16_loss: 0.6533 - dense_17_loss: 87.0887 - dense_16_acc: 0.7627 - dense_17_acc: 0.0760 - val_loss: 17.8170 - val_dense_16_loss: 0.3528 - val_dense_17_loss: 87.3214 - val_dense_16_acc: 0.8816 - val_dense_17_acc: 0.1323\n",
            "Epoch 18/30\n",
            "66771/66771 [==============================] - 47s 702us/step - loss: 18.0549 - dense_16_loss: 0.6370 - dense_17_loss: 87.0894 - dense_16_acc: 0.7696 - dense_17_acc: 0.0713 - val_loss: 17.7948 - val_dense_16_loss: 0.3288 - val_dense_17_loss: 87.3297 - val_dense_16_acc: 0.8976 - val_dense_17_acc: 0.1234\n",
            "Epoch 19/30\n",
            "66771/66771 [==============================] - 47s 702us/step - loss: 18.0407 - dense_16_loss: 0.6244 - dense_17_loss: 87.0813 - dense_16_acc: 0.7743 - dense_17_acc: 0.0840 - val_loss: 17.7784 - val_dense_16_loss: 0.3170 - val_dense_17_loss: 87.3074 - val_dense_16_acc: 0.8965 - val_dense_17_acc: 0.1459\n",
            "Epoch 20/30\n",
            "66771/66771 [==============================] - 47s 705us/step - loss: 18.0408 - dense_16_loss: 0.6244 - dense_17_loss: 87.0817 - dense_16_acc: 0.7770 - dense_17_acc: 0.0830 - val_loss: 17.7916 - val_dense_16_loss: 0.3257 - val_dense_17_loss: 87.3294 - val_dense_16_acc: 0.8933 - val_dense_17_acc: 0.1209\n",
            "Epoch 21/30\n",
            "66771/66771 [==============================] - 46s 696us/step - loss: 18.0264 - dense_16_loss: 0.6102 - dense_17_loss: 87.0810 - dense_16_acc: 0.7819 - dense_17_acc: 0.0843 - val_loss: 17.7823 - val_dense_16_loss: 0.3173 - val_dense_17_loss: 87.3250 - val_dense_16_acc: 0.8980 - val_dense_17_acc: 0.1251\n",
            "Epoch 22/30\n",
            "66771/66771 [==============================] - 46s 694us/step - loss: 18.0282 - dense_16_loss: 0.6121 - dense_17_loss: 87.0806 - dense_16_acc: 0.7809 - dense_17_acc: 0.0860 - val_loss: 17.7565 - val_dense_16_loss: 0.2942 - val_dense_17_loss: 87.3115 - val_dense_16_acc: 0.9032 - val_dense_17_acc: 0.1495\n",
            "Epoch 23/30\n",
            "66771/66771 [==============================] - 47s 698us/step - loss: 18.0135 - dense_16_loss: 0.5983 - dense_17_loss: 87.0759 - dense_16_acc: 0.7861 - dense_17_acc: 0.0905 - val_loss: 17.7536 - val_dense_16_loss: 0.2888 - val_dense_17_loss: 87.3238 - val_dense_16_acc: 0.9090 - val_dense_17_acc: 0.1248\n",
            "Epoch 24/30\n",
            "66771/66771 [==============================] - 48s 714us/step - loss: 18.0108 - dense_16_loss: 0.5962 - dense_17_loss: 87.0727 - dense_16_acc: 0.7890 - dense_17_acc: 0.0932 - val_loss: 17.7428 - val_dense_16_loss: 0.2819 - val_dense_17_loss: 87.3044 - val_dense_16_acc: 0.9098 - val_dense_17_acc: 0.1506\n",
            "Epoch 25/30\n",
            "66771/66771 [==============================] - 46s 693us/step - loss: 18.0002 - dense_16_loss: 0.5861 - dense_17_loss: 87.0703 - dense_16_acc: 0.7903 - dense_17_acc: 0.0975 - val_loss: 17.7262 - val_dense_16_loss: 0.2641 - val_dense_17_loss: 87.3106 - val_dense_16_acc: 0.9148 - val_dense_17_acc: 0.1408\n",
            "Epoch 26/30\n",
            "66771/66771 [==============================] - 47s 702us/step - loss: 17.9947 - dense_16_loss: 0.5805 - dense_17_loss: 87.0709 - dense_16_acc: 0.7921 - dense_17_acc: 0.0922 - val_loss: 17.7262 - val_dense_16_loss: 0.2640 - val_dense_17_loss: 87.3111 - val_dense_16_acc: 0.9148 - val_dense_17_acc: 0.1397\n",
            "Epoch 27/30\n",
            "66771/66771 [==============================] - 47s 697us/step - loss: 17.9927 - dense_16_loss: 0.5784 - dense_17_loss: 87.0717 - dense_16_acc: 0.7945 - dense_17_acc: 0.0946 - val_loss: 17.7102 - val_dense_16_loss: 0.2518 - val_dense_17_loss: 87.2922 - val_dense_16_acc: 0.9231 - val_dense_17_acc: 0.1626\n",
            "Epoch 28/30\n",
            "66771/66771 [==============================] - 46s 687us/step - loss: 17.9923 - dense_16_loss: 0.5782 - dense_17_loss: 87.0703 - dense_16_acc: 0.7950 - dense_17_acc: 0.0964 - val_loss: 17.7335 - val_dense_16_loss: 0.2748 - val_dense_17_loss: 87.2935 - val_dense_16_acc: 0.9096 - val_dense_17_acc: 0.1653\n",
            "Epoch 29/30\n",
            "66771/66771 [==============================] - 46s 685us/step - loss: 17.9787 - dense_16_loss: 0.5653 - dense_17_loss: 87.0671 - dense_16_acc: 0.7981 - dense_17_acc: 0.0997 - val_loss: 17.7230 - val_dense_16_loss: 0.2619 - val_dense_17_loss: 87.3056 - val_dense_16_acc: 0.9164 - val_dense_17_acc: 0.1516\n",
            "Epoch 30/30\n",
            "66771/66771 [==============================] - 46s 695us/step - loss: 17.9736 - dense_16_loss: 0.5605 - dense_17_loss: 87.0658 - dense_16_acc: 0.8023 - dense_17_acc: 0.1001 - val_loss: 17.6953 - val_dense_16_loss: 0.2344 - val_dense_17_loss: 87.3045 - val_dense_16_acc: 0.9281 - val_dense_17_acc: 0.1493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gycwvZgLX4HP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test_model_1(text, model):\n",
        "  print(text)\n",
        "  word_list = text_to_wordlist(text)\n",
        "  sequences = tokenizer.texts_to_sequences([word_list])\n",
        "  sequentes_input = list(itertools.chain(*sequences))\n",
        "  sequentes_input =  pad_sequences([sequentes_input], value=0, padding=\"post\", maxlen=windows_size).tolist()\n",
        "  input_a = np.asarray(sequentes_input)\n",
        "  pred = model.predict(input_a, batch_size=None, verbose=0, steps=None)\n",
        "  print(pred)\n",
        "  predicted_class = np.argmax(pred[0])\n",
        "  print(labels[predicted_class])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6dKARjI8XrPh",
        "colab_type": "code",
        "outputId": "6b0491a2-5c82-455c-885b-c21a99b2b64e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "cell_type": "code",
      "source": [
        "sen = \"All is going right with the party, I'm happy to know new people\"\n",
        "test_model_1(sen, model)\n",
        "sen = \"I want an ice cream and have some fries for lunch\"\n",
        "test_model_1(sen, model)\n",
        "sen = \"I'm afraid of lose my work, I don't have any money\"\n",
        "test_model_1(sen, model)\n",
        "sen = \"I'm worried about my future, I'm afroid of it\"\n",
        "test_model_1(sen, model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All is going right with the party, I'm happy to know new people\n",
            "[array([[0.69848865, 0.18393715, 0.09027162, 0.00608941, 0.02121312]],\n",
            "      dtype=float32), array([[0.9996779]], dtype=float32)]\n",
            "none\n",
            "I want an ice cream and have some fries for lunch\n",
            "[array([[0.09171404, 0.79242975, 0.10352303, 0.00707409, 0.00525908]],\n",
            "      dtype=float32), array([[0.9999982]], dtype=float32)]\n",
            "mild\n",
            "I'm afraid of lose my work, I don't have any money\n",
            "[array([[0.02358736, 0.00128106, 0.07346388, 0.8327862 , 0.06888146]],\n",
            "      dtype=float32), array([[0.9999999]], dtype=float32)]\n",
            "moderately severe\n",
            "I'm worried about my future, I'm afroid of it\n",
            "[array([[0.04125358, 0.00309274, 0.59854066, 0.01094239, 0.3461706 ]],\n",
            "      dtype=float32), array([[1.]], dtype=float32)]\n",
            "moderate\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}